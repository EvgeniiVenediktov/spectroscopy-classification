{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAMAN_DATASET_PATH = \"./data/raman_diabetis_spectroscopy/\"\n",
    "XENON_DATASET_PATH = \"./data/xenon/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name = 'vein'\n",
    "d = pd.read_csv(RAMAN_DATASET_PATH+dset_name+'.csv')\n",
    "d = d.iloc[1:,:]\n",
    "y = d.iloc[:,1].astype(int)\n",
    "# Trim data\n",
    "X = d.iloc[:,800:1800]\n",
    "# Make data zero-mean\n",
    "means = X.mean(0).to_frame().T\n",
    "means = means._append([means]*20, ignore_index=True).iloc[1:]\n",
    "X = X - means\n",
    "# Scale down the values\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_neg, y_neg = X[y==0], y[y==0]\n",
    "X_pos, y_pos = X[y==1], y[y==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.tensor(X.to_numpy(dtype=float)).to(torch.float32)\n",
    "tensor_y = torch.tensor(y.to_numpy(dtype=int)).to(torch.long)\n",
    "dataset = torch.utils.data.TensorDataset(tensor_x, tensor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1000, 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, 2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"mse_cpu\" not implemented for 'Int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m predicted \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mint()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Perform backward pass\u001b[39;00m\n\u001b[0;32m     59\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\EVV13\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\EVV13\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\EVV13\\.pyenv\\pyenv-win\\versions\\3.11.0\\Lib\\site-packages\\torch\\nn\\functional.py:3295\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m   3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[1;32m-> 3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"mse_cpu\" not implemented for 'Int'"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "# For fold results\n",
    "results = {}\n",
    "kf1 = KFold(n_splits=n, shuffle=True)\n",
    "kf2 = KFold(n_splits=n, shuffle=True)\n",
    "c = len(X_pos)\n",
    "fold = 0\n",
    "for train_pos, test_pos in kf1.split(X_pos):\n",
    "    for train_neg, test_neg in kf2.split(X_neg):\n",
    "        fold+=1\n",
    "        # print(\"%s %s %s %s\" % (train_pos, test_pos, train_neg+c, test_neg+c))\n",
    "        train_ids = [*train_pos, *train_neg]\n",
    "        test_ids = [*test_pos, *test_neg]\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "        \n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "                        dataset, \n",
    "                        batch_size=8, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=2, sampler=test_subsampler)\n",
    "        \n",
    "        # Init the neural network\n",
    "        network = MLP()\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n",
    "\n",
    "        # Run the training loop for defined number of epochs\n",
    "        for epoch in range(0, 30):\n",
    "\n",
    "            # Print epoch\n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "            # Set current loss value\n",
    "            current_loss = 0.0\n",
    "\n",
    "            # Iterate over the DataLoader for training data\n",
    "            i = 1 \n",
    "            for data in trainloader:\n",
    "                \n",
    "                # Get inputs\n",
    "                inputs, targets = data\n",
    "                targets = targets.int()\n",
    "                # Zero the gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Perform forward pass\n",
    "                outputs = network(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.int()\n",
    "                # Compute loss\n",
    "                loss = loss_function(predicted, targets)\n",
    "                \n",
    "                # Perform backward pass\n",
    "                loss.backward()\n",
    "                \n",
    "                # Perform optimization\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Print statistics\n",
    "                current_loss += loss.item()\n",
    "                if i % 2 == 1:\n",
    "                    print('Loss after mini-batch %5d: %.3f' %\n",
    "                        (i + 1, current_loss / 500))\n",
    "                    current_loss = 0.0\n",
    "                i+=1\n",
    "            # Process is complete.\n",
    "            print('Training process has finished. Saving trained model.')\n",
    "\n",
    "            # Print about testing\n",
    "            print('Starting testing')\n",
    "            \n",
    "            # Saving the model\n",
    "            save_path = f'./model-fold-{fold}.pth'\n",
    "            torch.save(network.state_dict(), save_path)\n",
    "\n",
    "            # Evaluationfor this fold\n",
    "            correct, total = 0, 0\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Iterate over the test data and generate predictions\n",
    "                for i, data in enumerate(testloader, 0):\n",
    "\n",
    "                    # Get inputs\n",
    "                    inputs, targets = data\n",
    "\n",
    "                    # Generate outputs\n",
    "                    outputs = network(inputs)\n",
    "\n",
    "                    # Set total and correct\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += targets.size(0)\n",
    "                    correct += (predicted == targets).sum().item()\n",
    "\n",
    "                # Print accuracy\n",
    "                print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "                print('--------------------------------')\n",
    "                results[fold] = 100.0 * (correct / total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=14, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=14, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.load_state_dict(torch.load('model-fold-4.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:  1\n",
      "true val: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EVV13\\AppData\\Local\\Temp\\ipykernel_28140\\2252768990.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  inp = torch.tensor(inp).float()\n"
     ]
    }
   ],
   "source": [
    "inp = X.iloc[0]\n",
    "label = y.iloc[0]\n",
    "inp = torch.tensor(inp).float()\n",
    "out = model(inp)\n",
    "print(\"predicted: \", int(torch.max(out.data, 0)[1]))\n",
    "print(\"true val:\" , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-14.5799,   7.9601]])\n",
      "torch.return_types.max(\n",
      "values=tensor([7.9601]),\n",
      "indices=tensor([1]))\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(torch.max(outputs.data, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP()\n",
    "model.load_state_dict(torch.load('model-fold-1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor(X.to_numpy()).float()\n",
    "best_model = None\n",
    "best_score = 0\n",
    "labels = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.6\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.6\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.55\n",
      "0.6\n",
      "0.55\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 26):\n",
    "    model = MLP()\n",
    "    model.load_state_dict(torch.load(f'model-fold-{i}.pth'))\n",
    "    out = model(inp)\n",
    "    _, preds = torch.max(out.data, 1)\n",
    "    preds = preds.numpy()\n",
    "    matches = labels[labels==preds]\n",
    "    score = len(matches)/len(labels)\n",
    "    print(score)\n",
    "    if score > best_score:\n",
    "        best_model = model\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
